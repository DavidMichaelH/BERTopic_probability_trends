{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install bertopic. If you see an error message regarding dependency conflicts then you should restart the runtime and run it again and it the message should disappear. "
      ],
      "metadata": {
        "id": "oggv3-kpCqRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic"
      ],
      "metadata": {
        "id": "QkVhnPbSayys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "id": "DglYMH8oDYh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from unidecode import unidecode\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import re\n",
        "from datetime import timedelta\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.dates as mdates"
      ],
      "metadata": {
        "id": "AFAabLAiQAfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = pd.read_csv('arxiv_with_subtopics_complete.csv',encoding = \"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "T8qNguFhZANM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fixes for some character encodings"
      ],
      "metadata": {
        "id": "0d6EhNIPQo1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unidecode import unidecode\n",
        "def fix_encoding(text):\n",
        "    text = text.encode('latin1').decode('utf-8')\n",
        "    text = unidecode(text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "-XXmiDayoWLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_encoding_subtopics = [fix_encoding(subtopic) for subtopic in df['subtopics']]\n",
        "fixed_encoding_subtopics[:10]"
      ],
      "metadata": {
        "id": "xT6aovZ1Qv89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "exclude = set(string.punctuation) - {'-'}\n",
        "\n",
        "def clean_text(subtopics):\n",
        "    cleaned = subtopics.encode('latin1').decode('utf-8')\n",
        "    cleaned = unidecode(cleaned)\n",
        "\n",
        "    # Remove double backslashes\n",
        "    cleaned = cleaned.replace('\\\\\\\\', '')\n",
        "\n",
        "    # Remove backslashes before double quotes\n",
        "    cleaned = cleaned.replace('\\\\\\\"', '\\\"')\n",
        "\n",
        "    # Remove quotes\n",
        "    cleaned = cleaned.replace('\\\"', '')\n",
        "\n",
        "    # Remove special characters except hyphen\n",
        "    cleaned = ''.join(ch for ch in cleaned if ch not in exclude)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "\n",
        "    # Convert to lowercase\n",
        "    cleaned = cleaned.lower()\n",
        "\n",
        "    return cleaned.strip()\n",
        "\n",
        "\n",
        "# Clean the subtopics for each abstract\n",
        "cleaned_subtopics = [clean_text(str(subtopics)) for subtopics in df['subtopics']]\n"
      ],
      "metadata": {
        "id": "Mae5XpVCoHU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_subtopics[:10]"
      ],
      "metadata": {
        "id": "CK_FbJNQoLAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean and add titles"
      ],
      "metadata": {
        "id": "OtR6oG-u72yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stop_words(text):\n",
        "  words = text.split(' ')\n",
        "  clean_text = ' '.join([word for word in words if word not in stop_words])\n",
        "  return clean_text\n"
      ],
      "metadata": {
        "id": "szqbd6ftSt0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_titles = [clean_text(str(title)) for title in df['title']]\n",
        "cleaned_titles = [remove_stop_words(str(title)) for title in cleaned_titles]\n",
        "cleaned_titles[:10]"
      ],
      "metadata": {
        "id": "hxuIb4Uv72DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles_and_topics = [cleaned_titles[i] + \" \" + cleaned_subtopics[i] for i in range(len(df))]\n",
        "titles_and_topics[:10]"
      ],
      "metadata": {
        "id": "dWMAZfgP8OEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering"
      ],
      "metadata": {
        "id": "fN2fI0N-cih1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from hdbscan import HDBSCAN\n",
        "from umap import UMAP\n",
        "\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=120, metric='euclidean', \n",
        "                        cluster_selection_method='eom', prediction_data=True, min_samples=5)\n",
        "\n",
        "umap_model = UMAP(n_neighbors=15, n_components=10, min_dist=0.0, metric='cosine', random_state=42)\n",
        " \n",
        "#embedding_model = SentenceTransformer(\"allenai-specter\")\n",
        "embedding_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
        "\n",
        "topic_model = BERTopic(umap_model = umap_model, hdbscan_model = hdbscan_model, \n",
        "                       verbose=True, embedding_model=embedding_model, min_topic_size=125)\n",
        "\n",
        "topics, probs = topic_model.fit_transform(titles_and_topics); \n",
        "len(topic_model.get_topic_info())"
      ],
      "metadata": {
        "id": "dGI6ofya4nOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic_info().head(50)"
      ],
      "metadata": {
        "id": "W8RbZ6X5d297"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_barchart(top_n_topics=20, height=700)\n"
      ],
      "metadata": {
        "id": "GwQQedPgYb_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_topics = topic_model.get_topic_info()"
      ],
      "metadata": {
        "id": "0PhEFrD-fygA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_topics.head(100)"
      ],
      "metadata": {
        "id": "wvH3N3KWCmng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_topics.sort_values(\"Count\", inplace=True)\n",
        "\n",
        "plt.barh(df_topics.Name.iloc[:-1],df_topics.Count.iloc[:-1])\n",
        "plt.rcParams.update({'font.size': 6})"
      ],
      "metadata": {
        "id": "oJZaUNlgYb_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_topics.sort_values(\"Topic\", inplace=True)"
      ],
      "metadata": {
        "id": "l67idSrxXJ2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = datetime.fromisoformat(df_data['date'].iloc[-1][:10])\n",
        "end_date = datetime.fromisoformat(df_data['date'].iloc[0][:10])\n",
        "num_days = (end_date - start_date).days\n",
        "\n",
        "def date_to_index(date):\n",
        "  index = date - start_date \n",
        "  return index.days\n"
      ],
      "metadata": {
        "id": "4VQvE2LaXqj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_by_topics = np.array([[0]*len(df_topics) for i in range(num_days)])\n",
        "current_date = datetime.fromisoformat(df_data['date'][0][:10])\n",
        "itr = 0\n",
        "while itr < len(df_data):\n",
        "  current_date = datetime.fromisoformat(df_data['date'][itr][:10])\n",
        "  index_date = date_to_index(current_date)-1\n",
        " \n",
        "  count_by_topics[index_date,topics[itr]+1] = count_by_topics[index_date,topics[itr]+1] + 1 \n",
        "  \n",
        "\n",
        "  itr = itr + 1 \n",
        " \n"
      ],
      "metadata": {
        "id": "S1JOjVWbVSUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cumsum_count_by_topics = np.cumsum(count_by_topics, axis = 0)"
      ],
      "metadata": {
        "id": "iGtShGn8dl9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myDates = [datetime(2017,12,31) for i in range(num_days)]\n",
        " \n",
        "numDates = mdates.date2num(myDates)\n",
        " \n"
      ],
      "metadata": {
        "id": "7hXMJwuXnTW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " \n",
        "df_topics.sort_values(\"Topic\", inplace=True)\n",
        "\n",
        "start_date = datetime(2017, 1, 1)\n",
        "\n",
        "num_days_offset = 365*3\n",
        "\n",
        "start_date = start_date + timedelta(days=num_days_offset)\n",
        "\n",
        "myDates = pd.date_range(start_date, periods=num_days-num_days_offset, freq='D')\n",
        "\n",
        "plt.figure(figsize=(16.75, 16.75))\n",
        "\n",
        "df = {'Date': myDates}\n",
        "df = pd.DataFrame(df)\n",
        "\n",
        "for k in range(1,cumsum_count_by_topics.shape[1]):\n",
        "    col_name = f'Line {k+1}'\n",
        "    df[col_name] = cumsum_count_by_topics[num_days_offset:,k]\n",
        "    sns.lineplot(data=df, x='Date', y=col_name,label=df_topics['Name'].iloc[k])\n",
        "\n",
        "plt.xlabel('Date')\n",
        "\n",
        "plt.ylabel('Number of Papers')\n",
        "\n",
        "plt.legend()\n",
        "plt.rcParams.update({'font.size': 8})\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "W7SBx1vFwEFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_topics()"
      ],
      "metadata": {
        "id": "dCYQvmEvLsTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_heatmap()"
      ],
      "metadata": {
        "id": "jfhfZZU4LsqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_hierarchy()"
      ],
      "metadata": {
        "id": "lEgN88juRrdi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}